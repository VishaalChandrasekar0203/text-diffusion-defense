# TextDiff

**Pre-trained LLM safety middleware with 2X better semantic preservation.**

```python
import textdiff
defense = textdiff.ControlDD()
clean_text = defense.get_clean_text_for_llm(user_prompt)
```

---

## ğŸ“‹ Overview

TextDiff is a lightweight, pre-trained library that protects Large Language Models from adversarial text attacks using embedding-based diffusion processes. It acts as a safety middleware layer between user input and LLM processing, cleaning potentially harmful prompts while preserving semantic meaning.

Unlike commercial solutions that destroy 63-71% of user intent, TextDiff maintains **69.3% semantic preservation** while providing robust safety controls. The system runs entirely locally on CPU, ensuring complete privacy and zero API costs.

**Key Innovation**: First application of diffusion models to LLM safety, achieving superior semantic preservation through embedding-space transformations.

---

## ğŸ“¦ Installation

```bash
pip install git+https://github.com/VishaalChandrasekar0203/text-diffusion-defense.git
```

---

## ğŸš€ Quick Start

### Simple Usage (3 Lines)
```python
import textdiff

defense = textdiff.ControlDD()
clean_text = defense.get_clean_text_for_llm(user_prompt)
# Send to your LLM
```

### Transparent Workflow
```python
import textdiff

defense = textdiff.ControlDD()
result = defense.analyze_and_respond(user_prompt)

if result['send_to_llm']:
    response = your_llm.generate(result['llm_prompt'])
    
elif result['status'] == 'needs_clarification':
    show_message(result['message_to_user'])
    user_choice = get_user_choice()  # 'original' or 'cleaned'
    
    verification = defense.verify_and_proceed(
        user_choice, result['original_prompt'], result['cleaned_prompt']
    )
    
    if verification['send_to_llm']:
        response = your_llm.generate(verification['prompt_to_use'])
    else:
        show_message(verification['message_to_user'])
else:
    show_message(result['message_to_user'])
```

---

## ğŸ¤– Quick Integration

### OpenAI
```python
import textdiff
import openai

defense = textdiff.ControlDD()
clean = defense.get_clean_text_for_llm(user_input)

response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": clean}]
)
```

### Anthropic
```python
import textdiff
import anthropic

defense = textdiff.ControlDD()
clean = defense.get_clean_text_for_llm(user_input)

client = anthropic.Client(api_key="key")
response = client.messages.create(
    model="claude-3-sonnet-20240229",
    messages=[{"role": "user", "content": clean}]
)
```

### Any LLM
```python
defense = textdiff.ControlDD()
clean = defense.get_clean_text_for_llm(user_input)
response = your_llm.generate(clean)  # Works with any LLM!
```

**More examples**: [research_details/INTEGRATION_GUIDE.md](research_details/INTEGRATION_GUIDE.md)

---

## ğŸ“Š Performance Benchmarks

| System | Safety Improvement | Semantic Preservation | Speed |
|--------|-------------------|----------------------|-------|
| **TextDiff** | 0.453 | **0.693** ğŸ† | 60ms |
| OpenAI Safety | 0.690 | 0.370 | 50ms |
| Anthropic Safety | 0.710 | 0.290 | 30ms |

**TextDiff delivers 2X better semantic preservation (69.3% vs 29-37%) while maintaining robust safety controls.**

**Training Data**: 17,715 adversarial-clean pairs  
**Model**: 500K parameters, 384-dim embeddings  
**Details**: [research_details/DATASET_AND_SCALING.md](research_details/DATASET_AND_SCALING.md)

---

## ğŸ”’ Safety Features

- **Multi-Category Detection**: 33+ patterns across 9 categories (violence, illegal, manipulation, hate, self-harm, terrorism)
- **Transparent Analysis**: Users see what was detected with clear explanations
- **Double Verification**: Re-verifies confirmations to prevent bypass attempts
- **Adaptive Thresholds**: Context-aware safety (educational, research, safety-critical)
- **Semantic Preservation**: Maintains 69.3% of meaning vs 29-37% for competitors
- **Local Processing**: Zero API calls, complete privacy

---

## ğŸ“ How It Works

1. **Input**: User prompt â†’ 384-dim embedding
2. **Analysis**: Pattern detection (9 categories)
3. **Diffusion**: 1000-step cleaning process
4. **Preservation**: Maintains semantic meaning
5. **Output**: Safe text for LLM

All local on CPU - no external APIs.

**Technical details**: [research_details/TECHNICAL_DETAILS.md](research_details/TECHNICAL_DETAILS.md)

---

## ğŸ“š Documentation

**Quick References:**
- **[INTEGRATION_GUIDE.md](research_details/INTEGRATION_GUIDE.md)** - Web apps, APIs, CLIs, serverless, mobile, and more (15+ examples)
- **[DATASET_AND_SCALING.md](research_details/DATASET_AND_SCALING.md)** - Training data (17,715 pairs), scaling forecasts, performance estimates
- **[TECHNICAL_DETAILS.md](research_details/TECHNICAL_DETAILS.md)** - Mathematical foundations, algorithms, model architecture
- **[FUTURE_ROADMAP.md](research_details/FUTURE_ROADMAP.md)** - Scaling plans, compute requirements, cost estimates

---

## ğŸ“‚ Project Structure

```
textdiff/
â”œâ”€â”€ README.md                  # Quick start (this file)
â”œâ”€â”€ demo.py                    # Usage examples
â”œâ”€â”€ textdiff/                  # Core library
â”‚   â”œâ”€â”€ control_dd.py         # ControlDD class
â”‚   â”œâ”€â”€ model.py              # Diffusion model
â”‚   â”œâ”€â”€ utils.py              # Utilities
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/                    # Pre-trained models
â”œâ”€â”€ research_details/          # Comprehensive documentation
â”‚   â”œâ”€â”€ INTEGRATION_GUIDE.md
â”‚   â”œâ”€â”€ DATASET_AND_SCALING.md
â”‚   â”œâ”€â”€ TECHNICAL_DETAILS.md
â”‚   â””â”€â”€ FUTURE_ROADMAP.md
â”œâ”€â”€ scripts/                   # Training methodology (reference)
â”œâ”€â”€ tests/                     # Test suite
â””â”€â”€ results/                   # Benchmarks
```

---

## ğŸ’¡ Impact

Efficient, cost-effective alternative to commercial LLM safety solutions. Enables organizations to implement robust safety without infrastructure costs. Local processing ensures privacy and reduces environmental impact.

---

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/VishaalChandrasekar0203/text-diffusion-defense/issues)
- **Email**: vishaalchandrasekar0203@gmail.com
- **Documentation**: [research_details/](research_details/) folder

---

## ğŸ“š Citation

```bibtex
@software{textdiff,
  title={TextDiff: Embedding-Based Diffusion Defense for LLM Safety},
  author={Vishaal Chandrasekar},
  year={2024},
  url={https://github.com/VishaalChandrasekar0203/text-diffusion-defense}
}
```

---

## ğŸ™ Acknowledgments

- Built on PyTorch and Transformers
- sentence-transformers/all-MiniLM-L6-v2 for embeddings
- Inspired by diffusion models (Ho et al., 2020)
- Training: aurora-m/adversarial-prompts (17,680 pairs) + synthetic (35 pairs)

---

*TextDiff - Simple, powerful, privacy-focused LLM safety*
